{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture-03 Gradient Descent and Dymanic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this week, we need complete following tasks:\n",
    "+ Re-review the course online programming; \n",
    "+ Choose 1 - 2 books which you interested and keep reading; \n",
    "+ Answer the review questions\n",
    "+ Prepare the basic requirement of our 1st project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I Review the online programming. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: change loss function from $loss = \\frac{1}{n}\\sum{(y_i - \\hat(y_i))^2}$ to $loss = \\frac{1}{n}\\sum{|y_i - \\hat{y_i}|}$, and using your mathmatical knowledge to get the right partial formual. Implemen the gradient descent code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': '/Users/hylan/anaconda3/lib/python3.7/site-packages/sklearn/datasets/data/boston_house_prices.csv'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "i =data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a26ae8dd8>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "k = random.randint(-100,100)\n",
    "b = random.randint(-100,100)\n",
    "\n",
    "def price_kb(k,b,r):\n",
    "    \n",
    "    return r*k + b\n",
    "    \n",
    "    \n",
    "x = [ _*0.1 for _ in range(90)]\n",
    "y = [price_kb(k,b,_)  for _ in x]\n",
    "\n",
    "plt.scatter(i[:,5], j)\n",
    "plt.scatter(i[:,5],[price_kb(9,-34,_)  for _ in i[:,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y1,y0):\n",
    "    \n",
    "    return sum([(_1-_0)**2/len(y1) for _1,_0 in zip(y1,y0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3483.9338228754946"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss([price_kb(k,b,_)  for _ in i[:,5]],j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "次数：1，loss值：5360106721.480501，k值：-10300，b值：-8100\n",
      "次数：3，loss值：2324571007.7358313，k值：6700，b值：5900\n",
      "次数：4，loss值：1429225159.3913226，k值：-4700，b值：-8100\n",
      "次数：5，loss值：260919494.78484195，k值：-3100，b值：3500\n",
      "次数：11，loss值：102849008.31164035，k值：-500，b值：13300\n",
      "次数：19，loss值：6389373.312272734，k值：-700，b值：6900\n",
      "次数：90，loss值：675864.9935375492，k值：900，b值：-5100\n",
      "次数：839，loss值：509057.78405138326，k值：700，b值：-4900\n",
      "次数：1015，loss值：395499.22278656164，k值：900，b值：-5700\n",
      "次数：1218，loss值：248218.9985968379，k值：100，b值：-1100\n",
      "次数：4062，loss值：28708.15084980238，k值：-100，b值：500\n"
     ]
    }
   ],
   "source": [
    "min_loss = float('inf')\n",
    "\n",
    "def calc_kb(ax,ay):\n",
    "    \n",
    "    number = 10000\n",
    "    while(number > 0):\n",
    "        k = random.randint(-100,100)*200 - 100\n",
    "        b = random.randint(-100,100)*200 - 100\n",
    "        \n",
    "        loss_value = loss([price_kb(k,b,_)  for _ in i[:,5]],j)\n",
    "        \n",
    "        global min_loss\n",
    "        \n",
    "        if loss_value < min_loss:\n",
    "            \n",
    "            print(\"次数：{}，loss值：{}，k值：{}，b值：{}\".format(10001 - number,loss_value,k,b))\n",
    "            \n",
    "            min_loss = loss_value\n",
    "            \n",
    "        number = number -1\n",
    "        \n",
    "calc_kb(i[:,5],j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "次数：1，loss值：88384.89667639475，k值：43.77818764279546，b值：43.62725094167739\n",
      "次数：2，loss值：87517.05069590459，k值：43.578187642795456，b值：43.427250941677386\n",
      "次数：3，loss值：86653.48940288424，k值：43.37818764279545，b值：43.22725094167738\n",
      "次数：4，loss值：85794.2127973337，k值：43.17818764279545，b值：43.02725094167738\n",
      "次数：5，loss值：84939.22087925319，k值：42.97818764279545，b值：42.82725094167738\n",
      "次数：6，loss值：84088.5136486425，k值：42.778187642795444，b值：42.627250941677374\n",
      "次数：7，loss值：83242.09110550169，k值：42.57818764279544，b值：42.42725094167737\n",
      "次数：8，loss值：82399.95324983065，k值：42.37818764279544，b值：42.22725094167737\n",
      "次数：9，loss值：81562.10008162961，k值：42.178187642795436，b值：42.027250941677366\n",
      "次数：10，loss值：80728.53160089847，k值：41.97818764279543，b值：41.82725094167736\n",
      "次数：11，loss值：79899.24780763713，k值：41.77818764279543，b值：41.62725094167736\n",
      "次数：12，loss值：79074.24870184562，k值：41.57818764279543，b值：41.42725094167736\n",
      "次数：13，loss值：78253.53428352418，k值：41.378187642795424，b值：41.227250941677354\n",
      "次数：14，loss值：77437.10455267256，k值：41.17818764279542，b值：41.02725094167735\n",
      "次数：15，loss值：76624.95950929083，k值：40.97818764279542，b值：40.82725094167735\n",
      "次数：16，loss值：75817.0991533789，k值：40.778187642795416，b值：40.627250941677346\n",
      "次数：17，loss值：75013.52348493689，k值：40.57818764279541，b值：40.42725094167734\n",
      "次数：18，loss值：74214.23250396475，k值：40.37818764279541，b值：40.22725094167734\n",
      "次数：19，loss值：73419.22621046258，k值：40.17818764279541，b值：40.02725094167734\n",
      "次数：20，loss值：72628.50460443019，k值：39.978187642795405，b值：39.827250941677335\n",
      "次数：21，loss值：71842.06768586782，k值：39.7781876427954，b值：39.62725094167733\n",
      "次数：22，loss值：71059.91545477507，k值：39.5781876427954，b值：39.42725094167733\n",
      "次数：23，loss值：70282.04791115243，k值：39.378187642795396，b值：39.227250941677326\n",
      "次数：24，loss值：69508.46505499964，k值：39.17818764279539，b值：39.02725094167732\n",
      "次数：25，loss值：68739.16688631669，k值：38.97818764279539，b值：38.82725094167732\n",
      "次数：26，loss值：67974.15340510354，k值：38.77818764279539，b值：38.62725094167732\n",
      "次数：27，loss值：67213.42461136034，k值：38.578187642795385，b值：38.427250941677315\n",
      "次数：28，loss值：66456.98050508699，k值：38.37818764279538，b值：38.22725094167731\n",
      "次数：29，loss值：65704.82108628367，k值：38.17818764279538，b值：38.02725094167731\n",
      "次数：30，loss值：64956.946354950014，k值：37.978187642795376，b值：37.827250941677306\n",
      "次数：31，loss值：64213.356311086434，k值：37.77818764279537，b值：37.6272509416773\n",
      "次数：32，loss值：63474.05095469266，k值：37.57818764279537，b值：37.4272509416773\n",
      "次数：33，loss值：62739.030285768815，k值：37.37818764279537，b值：37.2272509416773\n",
      "次数：34，loss值：62008.29430431471，k值：37.178187642795365，b值：37.027250941677295\n",
      "次数：35，loss值：61281.843010330565，k值：36.97818764279536，b值：36.82725094167729\n",
      "次数：36，loss值：60559.6764038163，k值：36.77818764279536，b值：36.62725094167729\n",
      "次数：37，loss值：59841.79448477198，k值：36.578187642795356，b值：36.427250941677286\n",
      "次数：38，loss值：59128.19725319744，k值：36.37818764279535，b值：36.22725094167728\n",
      "次数：39，loss值：58418.8847090928，k值：36.17818764279535，b值：36.02725094167728\n",
      "次数：40，loss值：57713.85685245806，k值：35.97818764279535，b值：35.82725094167728\n",
      "次数：41，loss值：57013.113683293195，k值：35.778187642795345，b值：35.627250941677275\n",
      "次数：42，loss值：56316.65520159828，k值：35.57818764279534，b值：35.42725094167727\n",
      "次数：43，loss值：55624.48140737324，k值：35.37818764279534，b值：35.22725094167727\n",
      "次数：44，loss值：54936.59230061802，k值：35.178187642795336，b值：35.027250941677266\n",
      "次数：45，loss值：54252.98788133263，k值：34.97818764279533，b值：34.82725094167726\n",
      "次数：46，loss值：53573.66814951724，k值：34.77818764279533，b值：34.62725094167726\n",
      "次数：47，loss值：52898.633105171684，k值：34.57818764279533，b值：34.42725094167726\n",
      "次数：48，loss值：52227.88274829598，k值：34.378187642795325，b值：34.227250941677255\n",
      "次数：49，loss值：51561.41707889026，k值：34.17818764279532，b值：34.02725094167725\n",
      "次数：50，loss值：50899.236096954286，k值：33.97818764279532，b值：33.82725094167725\n",
      "次数：51，loss值：50241.33980248825，k值：33.77818764279532，b值：33.62725094167725\n",
      "次数：52，loss值：49587.72819549209，k值：33.578187642795314，b值：33.427250941677244\n",
      "次数：53，loss值：48938.40127596585，k值：33.37818764279531，b值：33.22725094167724\n",
      "次数：54，loss值：48293.3590439095，k值：33.17818764279531，b值：33.02725094167724\n",
      "次数：55，loss值：47652.60149932295，k值：32.978187642795305，b值：32.827250941677235\n",
      "次数：56，loss值：47016.128642206364，k值：32.7781876427953，b值：32.62725094167723\n",
      "次数：57，loss值：46383.94047255961，k值：32.5781876427953，b值：32.42725094167723\n",
      "次数：58，loss值：45756.03699038277，k值：32.3781876427953，b值：32.22725094167723\n",
      "次数：59，loss值：45132.41819567573，k值：32.178187642795294，b值：32.027250941677224\n",
      "次数：60，loss值：44513.08408843868，k值：31.978187642795294，b值：31.827250941677224\n",
      "次数：61，loss值：43898.03466867147，k值：31.778187642795295，b值：31.627250941677225\n",
      "次数：62，loss值：43287.26993637413，k值：31.578187642795296，b值：31.427250941677226\n",
      "次数：63，loss值：42680.78989154671，k值：31.378187642795297，b值：31.227250941677227\n",
      "次数：64，loss值：42078.59453418911，k值：31.178187642795297，b值：31.027250941677227\n",
      "次数：65，loss值：41480.68386430144，k值：30.978187642795298，b值：30.827250941677228\n",
      "次数：66，loss值：40887.05788188362，k值：30.7781876427953，b值：30.62725094167723\n",
      "次数：67，loss值：40297.71658693572，k值：30.5781876427953，b值：30.42725094167723\n",
      "次数：68，loss值：39712.65997945771，k值：30.3781876427953，b值：30.22725094167723\n",
      "次数：69，loss值：39131.8880594495，k值：30.1781876427953，b值：30.02725094167723\n",
      "次数：70，loss值：38555.40082691127，k值：29.9781876427953，b值：29.82725094167723\n",
      "次数：71，loss值：37983.198281842844，k值：29.778187642795302，b值：29.627250941677232\n",
      "次数：72，loss值：37415.28042424437，k值：29.578187642795303，b值：29.427250941677233\n",
      "次数：73，loss值：36851.64725411567，k值：29.378187642795304，b值：29.227250941677234\n",
      "次数：74，loss值：36292.29877145702，k值：29.178187642795304，b值：29.027250941677234\n",
      "次数：75，loss值：35737.23497626813，k值：28.978187642795305，b值：28.827250941677235\n",
      "次数：76，loss值：35186.45586854915，k值：28.778187642795306，b值：28.627250941677236\n",
      "次数：77，loss值：34639.961448300026，k值：28.578187642795307，b值：28.427250941677237\n",
      "次数：78，loss值：34097.75171552081，k值：28.378187642795307，b值：28.227250941677237\n",
      "次数：79，loss值：33559.826670211434，k值：28.178187642795308，b值：28.027250941677238\n",
      "次数：80，loss值：33026.18631237201，k值：27.97818764279531，b值：27.82725094167724\n",
      "次数：81，loss值：32496.830642002402，k值：27.77818764279531，b值：27.62725094167724\n",
      "次数：82，loss值：31971.759659102747，k值：27.57818764279531，b值：27.42725094167724\n",
      "次数：83，loss值：31450.97336367291，k值：27.37818764279531，b值：27.22725094167724\n",
      "次数：84，loss值：30934.471755713，k值：27.17818764279531，b值：27.02725094167724\n",
      "次数：85，loss值：30422.254835222935，k值：26.978187642795312，b值：26.827250941677242\n",
      "次数：86，loss值：29914.32260220275，k值：26.778187642795313，b值：26.627250941677243\n",
      "次数：87，loss值：29410.675056652468，k值：26.578187642795314，b值：26.427250941677244\n",
      "次数：88，loss值：28911.31219857205，k值：26.378187642795314，b值：26.227250941677244\n",
      "次数：89，loss值：28416.23402796153，k值：26.178187642795315，b值：26.027250941677245\n",
      "次数：90，loss值：27925.440544820878，k值：25.978187642795316，b值：25.827250941677246\n",
      "次数：91，loss值：27438.93174915013，k值：25.778187642795316，b值：25.627250941677246\n",
      "次数：92，loss值：26956.707640949207，k值：25.578187642795317，b值：25.427250941677247\n",
      "次数：93，loss值：26478.768220218222，k值：25.378187642795318，b值：25.227250941677248\n",
      "次数：94，loss值：26005.11348695707，k值：25.17818764279532，b值：25.02725094167725\n",
      "次数：95，loss值：25535.743441165858，k值：24.97818764279532，b值：24.82725094167725\n",
      "次数：96，loss值：25070.658082844504，k值：24.77818764279532，b值：24.62725094167725\n",
      "次数：97，loss值：24609.85741199303，k值：24.57818764279532，b值：24.42725094167725\n",
      "次数：98，loss值：24153.341428611457，k值：24.37818764279532，b值：24.22725094167725\n",
      "次数：99，loss值：23701.110132699727，k值：24.178187642795322，b值：24.027250941677252\n",
      "次数：100，loss值：23253.163524257896，k值：23.978187642795323，b值：23.827250941677253\n",
      "次数：101，loss值：22809.50160328591，k值：23.778187642795324，b值：23.627250941677254\n",
      "次数：102，loss值：22370.12436978386，k值：23.578187642795324，b值：23.427250941677254\n",
      "次数：103，loss值：21935.0318237517，k值：23.378187642795325，b值：23.227250941677255\n",
      "次数：104，loss值：21504.223965189398，k值：23.178187642795326，b值：23.027250941677256\n",
      "次数：105，loss值：21077.70079409696，k值：22.978187642795326，b值：22.827250941677256\n",
      "次数：106，loss值：20655.462310474424，k值：22.778187642795327，b值：22.627250941677257\n",
      "次数：107，loss值：20237.50851432176，k值：22.578187642795328，b值：22.427250941677258\n",
      "次数：108，loss值：19823.839405638944，k值：22.37818764279533，b值：22.22725094167726\n",
      "次数：109，loss值：19414.454984426076，k值：22.17818764279533，b值：22.02725094167726\n",
      "次数：110，loss值：19009.35525068303，k值：21.97818764279533，b值：21.82725094167726\n",
      "次数：111，loss值：18608.540204409906，k值：21.77818764279533，b值：21.62725094167726\n",
      "次数：112，loss值：18212.009845606673，k值：21.57818764279533，b值：21.42725094167726\n",
      "次数：113，loss值：17819.764174273278，k值：21.378187642795332，b值：21.227250941677262\n",
      "次数：114，loss值：17431.8031904098，k值：21.178187642795333，b值：21.027250941677263\n",
      "次数：115，loss值：17048.126894016183，k值：20.978187642795334，b值：20.827250941677264\n",
      "次数：116，loss值：16668.735285092447，k值：20.778187642795334，b值：20.627250941677264\n",
      "次数：117，loss值：16293.628363638614，k值：20.578187642795335，b值：20.427250941677265\n",
      "次数：118，loss值：15922.80612965464，k值：20.378187642795336，b值：20.227250941677266\n",
      "次数：119，loss值：15556.268583140554，k值：20.178187642795336，b值：20.027250941677266\n",
      "次数：120，loss值：15194.015724096336，k值：19.978187642795337，b值：19.827250941677267\n",
      "次数：121，loss值：14836.047552522026，k值：19.778187642795338，b值：19.627250941677268\n",
      "次数：122，loss值：14482.36406841758，k值：19.57818764279534，b值：19.42725094167727\n",
      "次数：123，loss值：14132.965271783012，k值：19.37818764279534，b值：19.22725094167727\n",
      "次数：124，loss值：13787.851162618352，k值：19.17818764279534，b值：19.02725094167727\n",
      "次数：125，loss值：13447.021740923548，k值：18.97818764279534，b值：18.82725094167727\n",
      "次数：126，loss值：13110.477006698646，k值：18.77818764279534，b值：18.62725094167727\n",
      "次数：127，loss值：12778.21695994361，k值：18.578187642795342，b值：18.427250941677272\n",
      "次数：128，loss值：12450.241600658424，k值：18.378187642795343，b值：18.227250941677273\n",
      "次数：129，loss值：12126.550928843177，k值：18.178187642795343，b值：18.027250941677273\n",
      "次数：130，loss值：11807.14494449777，k值：17.978187642795344，b值：17.827250941677274\n",
      "次数：131，loss值：11492.023647622276，k值：17.778187642795345，b值：17.627250941677275\n",
      "次数：132，loss值：11181.18703821665，k值：17.578187642795346，b值：17.427250941677276\n",
      "次数：133，loss值：10874.635116280895，k值：17.378187642795346，b值：17.227250941677276\n",
      "次数：134，loss值：10572.36788181503，k值：17.178187642795347，b值：17.027250941677277\n",
      "次数：135，loss值：10274.385334819053，k值：16.978187642795348，b值：16.827250941677278\n",
      "次数：136，loss值：9980.687475292958，k值：16.77818764279535，b值：16.62725094167728\n",
      "次数：137，loss值：9691.274303236736，k值：16.57818764279535，b值：16.42725094167728\n",
      "次数：138，loss值：9406.145818650399，k值：16.37818764279535，b值：16.22725094167728\n",
      "次数：139，loss值：9125.302021533935，k值：16.17818764279535，b值：16.02725094167728\n",
      "次数：140，loss值：8848.742911887353，k值：15.978187642795351，b值：15.827250941677281\n",
      "次数：141，loss值：8576.468489710667，k值：15.778187642795352，b值：15.627250941677282\n",
      "次数：142，loss值：8308.478755003836，k值：15.578187642795353，b值：15.427250941677283\n",
      "次数：143，loss值：8044.773707766915，k值：15.378187642795353，b值：15.227250941677283\n",
      "次数：144，loss值：7785.353347999863，k值：15.178187642795354，b值：15.027250941677284\n",
      "次数：145，loss值：7530.21767570269，k值：14.978187642795355，b值：14.827250941677285\n",
      "次数：146，loss值：7279.366690875406，k值：14.778187642795356，b值：14.627250941677286\n",
      "次数：147，loss值：7032.800393518004，k值：14.578187642795356，b值：14.427250941677286\n",
      "次数：148，loss值：6790.518783630474，k值：14.378187642795357，b值：14.227250941677287\n",
      "次数：149，loss值：6552.521861212831，k值：14.178187642795358，b值：14.027250941677288\n",
      "次数：150，loss值：6318.809626265073，k值：13.978187642795358，b值：13.827250941677288\n",
      "次数：151，loss值：6089.382078787194，k值：13.77818764279536，b值：13.62725094167729\n",
      "次数：152，loss值：5864.239218779191，k值：13.57818764279536，b值：13.42725094167729\n",
      "次数：153，loss值：5643.381046241074，k值：13.37818764279536，b值：13.22725094167729\n",
      "次数：154，loss值：5426.807561172841，k值：13.178187642795361，b值：13.027250941677291\n",
      "次数：155，loss值：5214.518763574487，k值：12.978187642795362，b值：12.827250941677292\n",
      "次数：156，loss值：5006.514653446003，k值：12.778187642795363，b值：12.627250941677293\n",
      "次数：157，loss值：4802.79523078741，k值：12.578187642795363，b值：12.427250941677293\n",
      "次数：158，loss值：4603.360495598702，k值：12.378187642795364，b值：12.227250941677294\n",
      "次数：159，loss值：4408.210447879872，k值：12.178187642795365，b值：12.027250941677295\n",
      "次数：160，loss值：4217.345087630924，k值：11.978187642795366，b值：11.827250941677296\n",
      "次数：161，loss值：4030.7644148518593，k值：11.778187642795366，b值：11.627250941677296\n",
      "次数：162，loss值：3848.4684295426714，k值：11.578187642795367，b值：11.427250941677297\n",
      "次数：163，loss值：3670.4571317033683，k值：11.378187642795368，b值：11.227250941677298\n",
      "次数：164，loss值：3496.730521333947，k值：11.178187642795368，b值：11.027250941677298\n",
      "次数：165，loss值：3327.288598434404，k值：10.978187642795369，b值：10.827250941677299\n",
      "次数：166，loss值：3162.1313630047434，k值：10.77818764279537，b值：10.6272509416773\n",
      "次数：167，loss值：3001.258815044966，k值：10.57818764279537，b值：10.4272509416773\n",
      "次数：168，loss值：2844.6709545550675，k值：10.378187642795371，b值：10.227250941677301\n",
      "次数：169，loss值：2692.3677815350547，k值：10.178187642795372，b值：10.027250941677302\n",
      "次数：170，loss值：2544.3492959849173，k值：9.978187642795373，b值：9.827250941677303\n",
      "次数：171，loss值：2400.6154979046655，k值：9.778187642795373，b值：9.627250941677303\n",
      "次数：172，loss值：2261.1663872942913，k值：9.578187642795374，b值：9.427250941677304\n",
      "次数：173，loss值：2126.0019641538033，k值：9.378187642795375，b值：9.227250941677305\n",
      "次数：174，loss值：1995.122228483193，k值：9.178187642795375，b值：9.027250941677305\n",
      "次数：175，loss值：1868.5271802824673，k值：8.978187642795376，b值：8.827250941677306\n",
      "次数：176，loss值：1746.216819551621，k值：8.778187642795377，b值：8.627250941677307\n",
      "次数：177，loss值：1628.1911462906571，k值：8.578187642795378，b值：8.427250941677308\n",
      "次数：178，loss值：1514.4501604995742，k值：8.378187642795378，b值：8.227250941677308\n",
      "次数：179，loss值：1404.9938621783708，k值：8.178187642795379，b值：8.027250941677309\n",
      "次数：180，loss值：1299.8222513270505，k值：7.978187642795379，b值：7.827250941677309\n",
      "次数：181，loss值：1198.9353279456107，k值：7.778187642795379，b值：7.627250941677309\n",
      "次数：182，loss值：1102.3330920340527，k值：7.5781876427953785，b值：7.4272509416773085\n",
      "次数：183，loss值：1010.0155435923748，k值：7.378187642795378，b值：7.227250941677308\n",
      "次数：184，loss值：921.982682620581，k值：7.178187642795378，b值：7.027250941677308\n",
      "次数：185，loss值：838.234509118666，k值：6.978187642795378，b值：6.827250941677308\n",
      "次数：186，loss值：758.7710230866335，k值：6.778187642795378，b值：6.627250941677308\n",
      "次数：187，loss值：683.5922245244831，k值：6.578187642795378，b值：6.427250941677308\n",
      "次数：188，loss值：612.6981134322131，k值：6.378187642795377，b值：6.227250941677307\n",
      "次数：189，loss值：546.0886898098257，k值：6.178187642795377，b值：6.027250941677307\n",
      "次数：190，loss值：483.7639536573185，k值：5.978187642795377，b值：5.827250941677307\n",
      "次数：191，loss值：425.7239049746934，k值：5.778187642795377，b值：5.627250941677307\n",
      "次数：192，loss值：371.9685437619498，k值：5.578187642795377，b值：5.427250941677307\n",
      "次数：193，loss值：322.4978700190872，k值：5.3781876427953765，b值：5.2272509416773065\n",
      "次数：194，loss值：277.3118837461064，k值：5.178187642795376，b值：5.027250941677306\n",
      "次数：195，loss值：236.4105849430067，k值：4.978187642795376，b值：4.827250941677306\n",
      "次数：196，loss值：199.79397360978868，k值：4.778187642795376，b值：4.627250941677306\n",
      "次数：197，loss值：167.462049746452，k值：4.578187642795376，b值：4.427250941677306\n",
      "次数：198，loss值：139.41481335299687，k值：4.378187642795376，b值：4.227250941677306\n",
      "次数：199，loss值：115.6522644294229，k值：4.1781876427953755，b值：4.0272509416773055\n",
      "次数：200，loss值：96.17440297573059，k值：3.9781876427953753，b值：3.8272509416773053\n",
      "次数：201，loss值：80.98122899191968，k值：3.778187642795375，b值：3.627250941677305\n",
      "次数：202，loss值：70.07274247799016，k值：3.578187642795375，b值：3.427250941677305\n",
      "次数：203，loss值：63.448943433942055，k值：3.3781876427953748，b值：3.2272509416773048\n",
      "次数：204，loss值：61.10983185977543，k值：3.1781876427953746，b值：3.0272509416773046\n"
     ]
    }
   ],
   "source": [
    "direction = [(+1, -1),(+1, +1), (-1, -1),(-1, +1)]\n",
    "\n",
    "next_direction = random.choice(direction)\n",
    "\n",
    "min_loss = float('inf')\n",
    "\n",
    "k = random.random()*200 - 100\n",
    "b = random.random()*200 - 100\n",
    "\n",
    "scalar = 0.2\n",
    "\n",
    "    \n",
    "number = 2000\n",
    "\n",
    "while(number > 0):\n",
    "\n",
    "    k_direction,b_direction = next_direction\n",
    "\n",
    "    loss_value = loss([price_kb(k + k_direction * scalar,b + b_direction * scalar , _ )  for _ in i[:,5]],j)\n",
    "\n",
    "    if loss_value < min_loss:\n",
    "\n",
    "        print(\"次数：{}，loss值：{}，k值：{}，b值：{}\".format(2001 - number,loss_value,k + k_direction * scalar,b + b_direction * scalar ))\n",
    "\n",
    "        min_loss = loss_value\n",
    "\n",
    "        next_direction = next_direction\n",
    "        \n",
    "        k,b = k + k_direction * scalar,b + b_direction * scalar\n",
    "    else :\n",
    "\n",
    "        next_direction = random.choice(direction)\n",
    "\n",
    "    number = number -1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##采用梯度变化来控制方向(1)\n",
    "\n",
    "目标loss=sum（(y_actual - y_target)**2），变量为k和b\n",
    "\n",
    "y_actual模型：kx+b\n",
    "\n",
    "目标是找到一组k，b，使得loss取得最小值。---->越来越小。\n",
    "\n",
    "\n",
    "loss|k梯度：sum（2（y_actual-y_target）* x）\n",
    "\n",
    "loos|b梯度：sum（2（y_atctual-y_target））\n",
    "\n",
    "当梯度为症，且更大的时候，loss值变化越快，也更大。\n",
    "\n",
    "为了使loss越来越小，k、b应该不断变化。k、b应该向梯度的反方向变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#梯度计算函数\n",
    "\n",
    "def k_gradient(x,y_actual,y_target):\n",
    "    \n",
    "    return sum([2*(y_a - y_t)*x_  for x_,y_a,y_t in zip(x,y_actual,y_target)])/len(y_target)\n",
    "\n",
    "def b_gradient(y_actual,y_target):\n",
    "    \n",
    "    return sum([2*(y_a - y_t)  for y_a,y_t in zip(y_actual,y_target)])/len(y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "次数：1，loss值：6290.114937675972，k值：-4.911089487778213，b值：-25.02322254953296\n",
      "次数：101，loss值：1249.5665263290955，k值：1.929067523323508，b值：-23.950764529812336\n",
      "次数：201，loss值：277.4989701412422，k值：4.933141937330307，b值：-23.481357456988068\n",
      "次数：301，loss值：90.03565159480883，k值：6.252614975182134，b值：-23.27677757595644\n",
      "次数：401，loss值：53.8828178827374，k值：6.832301563855361，b值：-23.188495190445323\n",
      "次数：501，loss值：46.910126103163314，k值：7.087113642885518，b值：-23.151284040250633\n",
      "次数：601，loss值：45.56480853764926，k值：7.199258237861798，b值：-23.136500257381744\n",
      "次数：701，loss值：45.304727220866，k值：7.2487508822357505，b值：-23.131564994490923\n",
      "次数：801，loss值：45.253933408889935，k值：7.270730098104859，b值：-23.13095429792764\n",
      "次数：901，loss值：45.24350088054992，k值：7.280626835967987，b值：-23.132242344207906\n"
     ]
    }
   ],
   "source": [
    "min_loss = float('inf')\n",
    "\n",
    "k = random.random()*200 - 100\n",
    "b = random.random()*200 - 100\n",
    "\n",
    "scaler = 0.0001\n",
    "    \n",
    "number = 1000\n",
    "\n",
    "while(number > 0):\n",
    "\n",
    "    loss_value = loss([price_kb(k,b,_) for _ in i[:,5]],j)\n",
    "\n",
    "    if number %100 == 0:\n",
    "\n",
    "        print(\"次数：{}，loss值：{}，k值：{}，b值：{}\".format(1001 - number,loss_value,k,b))\n",
    "\n",
    "        min_loss = loss_value\n",
    "    \n",
    "    k,b = k + (-1) * k_gradient(i[:,5],[k*x_+b for x_ in i[:,5]],j) *scaler,b + (-1) * b_gradient([k*x_+b for x_ in i[:,5]],j)*scaler\n",
    "\n",
    "    number = number -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##采用梯度变化来控制方向(2)\n",
    "\n",
    "目标loss=sum（|y_actual - y_target|），变量为k和b\n",
    "\n",
    "y_actual模型：kx+b\n",
    "\n",
    "目标是找到一组k，b，使得loss取得最小值。---->越来越小。\n",
    "\n",
    "\n",
    "loss|k梯度：sum（x）|y_actual > y_target + sum(-x)|y_actual<=y_target\n",
    "\n",
    "loos|b梯度：sum（1）|y_actual > y_target + sum(-1)|y_actual<=y_target\n",
    "\n",
    "当梯度为正，且更大的时候，loss值变化越快，也更大。\n",
    "\n",
    "为了使loss越来越小，k、b应该不断变化。k、b应该向梯度的反方向变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#梯度计算函数及loss值计算\n",
    "\n",
    "def k_gradient_abs(x,y_actual,y_target):\n",
    "    \n",
    "    sum_1 =sum_2 = 0\n",
    "    \n",
    "    for x_,y_a,y_t in zip(x,y_actual,y_target):\n",
    "        \n",
    "        if (y_a>y_t): sum_1 += x_\n",
    "            \n",
    "        if (y_a<=y_t): sum_2 += (-1) * x_\n",
    "    \n",
    "    return (sum_1 + sum_2)/len(y_target)\n",
    "\n",
    "def b_gradient_abs(y_actual,y_target):\n",
    "    \n",
    "    sum_1 =sum_2 = 0\n",
    "    \n",
    "    for y_a,y_t in zip(y_actual,y_target):\n",
    "        \n",
    "        if (y_a>y_t): sum_1 += 1\n",
    "            \n",
    "        if (y_a<=y_t): sum_2 += (-1)\n",
    "    \n",
    "    return (sum_1 + sum_2)/len(y_target)\n",
    "\n",
    "def loss_abs(y_actual,y_target):\n",
    "    \n",
    "    return sum([abs(y_a -y_b) for y_a,y_b in zip(y_actual,y_target)])/len(y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "次数：1，loss值：26.633239397772734，k值：-4.394346604783152，b值：76.14383484669648\n",
      "次数：1001，loss值：23.683711232078164，k值：-4.930231015059883，b值：76.05573603246727\n",
      "次数：2001，loss值：20.852676140516863，k值：-5.455200102016419，b值：75.96914472811879\n",
      "次数：3001，loss值：18.40847650493077，k值：-5.942616420593539，b值：75.88783247515453\n",
      "次数：4001，loss值：16.442458671483358，k值：-6.37958423917056，b值：75.81351785064955\n",
      "次数：5001，loss值：14.808372776835562，k值：-6.777699857747723，b值：75.74479690203346\n",
      "次数：6001，loss值：13.481387580117707，k值：-7.136252994111225，b值：75.68191389808175\n",
      "次数：7001，loss值：12.470965303892324，k值：-7.449006964071663，b值：75.6258470996629\n",
      "次数：8001，loss值：11.637378443520442，k值：-7.733014424150643，b值：75.57410006408895\n",
      "次数：9001，loss值：11.018284973820728，k值：-7.9768847364034805，b值：75.52842970835769\n"
     ]
    }
   ],
   "source": [
    "min_loss = float('inf')\n",
    "\n",
    "k = random.random()*200 - 100\n",
    "b = random.random()*200 - 100\n",
    "\n",
    "#k = 11\n",
    "#b = -46\n",
    "scaler = 0.0001\n",
    "    \n",
    "number = 10000\n",
    "\n",
    "while(number > 0):\n",
    "\n",
    "    loss_value = loss_abs([price_kb(k,b,_)  for _ in i[:,5]],j)\n",
    "\n",
    "    if number %1000 == 0:\n",
    "\n",
    "        print(\"次数：{}，loss值：{}，k值：{}，b值：{}\".format(10001 - number,loss_value,k,b))\n",
    "\n",
    "        min_loss = loss_value\n",
    "    \n",
    "    k,b = k + (-1) * k_gradient_abs(i[:,5],[k*x_+b for x_ in i[:,5]],j) *scaler,b + (-1) * b_gradient_abs([k*x_+b for x_ in i[:,5]],j)*scaler\n",
    "\n",
    "    number = number -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Finish the Solution Parse Part of Edit-Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "solution = {}\n",
    "\n",
    "candidates = []\n",
    "\n",
    "distance_need = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lru_cache(maxsize):\n",
    "    \n",
    "    def decoartor(f):\n",
    "    \n",
    "        def wrap(string1,string2):\n",
    "\n",
    "            if (string1,string2) in solution:\n",
    "\n",
    "                return distance_need[(string1,string2)]\n",
    "\n",
    "            result = f(string1,string2)\n",
    "\n",
    "            distance_need[(string1,string2)] = result\n",
    "\n",
    "            return result\n",
    "\n",
    "        return wrap\n",
    "    \n",
    "    return decoartor\n",
    "\n",
    "@lru_cache(maxsize=2**10)\n",
    "def edit_distance(string1, string2):\n",
    "    \n",
    "    if len(string1) == 0: return len(string2)\n",
    "    if len(string2) == 0: return len(string1)\n",
    "    \n",
    "    tail_s1 = string1[-1]\n",
    "    tail_s2 = string2[-1]\n",
    "    \n",
    "    global candidates\n",
    "    candidates = [\n",
    "        (edit_distance(string1[:-1], string2) + 1, 'DEL {}'.format(tail_s1)),  # string 1 delete tail\n",
    "        (edit_distance(string1, string2[:-1]) + 1, 'ADD {}'.format(tail_s2)),  # string 1 add tail of string2\n",
    "    ]\n",
    "    \n",
    "    if tail_s1 == tail_s2:\n",
    "        both_forward = (edit_distance(string1[:-1], string2[:-1]) + 0, '')\n",
    "    else:\n",
    "        both_forward = (edit_distance(string1[:-1], string2[:-1]) + 1, 'SUB {} => {}'.format(tail_s1, tail_s2))\n",
    "\n",
    "    candidates.append(both_forward)\n",
    "    \n",
    "    min_distance, operation = min(candidates, key=lambda x: x[0])\n",
    "    #print(min_distance,\"i_need:\"+operation)\n",
    "    solution[(string1, string2)] = operation \n",
    "    \n",
    "    return min_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_distance('ABCDE', 'ABCCEF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser_solution(string1,string2,solution):\n",
    "    \n",
    "    distance = edit_distance(string1,string2)\n",
    "    \n",
    "    def steps(string1,string2,solution):\n",
    "    \n",
    "        if (string1==string2):\n",
    "\n",
    "             return ()\n",
    "\n",
    "        if (len(string1) > len(string2)):\n",
    "\n",
    "            return (solution[(string1,string2)],) + steps(string1[:-1],string2,solution)\n",
    "\n",
    "        if len(string1) == len(string2):\n",
    "            return (solution[(string1,string2)],) + steps(string1[:-1],string2[:-1],solution)\n",
    "\n",
    "        if len(string1) < len(string2):\n",
    "            return steps(string1,string2[:-1],solution) + (solution[(string1,string2)],)\n",
    "        \n",
    "    steps_list = [x for x in steps(string1,string2,solution) if x !='']\n",
    "    \n",
    "    return ('由右边往左编辑，总步数：{}'.format(str(distance)),steps_list) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('由右边往左编辑，总步数：5', ['SUB C => E', 'ADD F', 'ADD F', 'ADD G', 'ADD M'])"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser_solution('ABC', 'ABEFFGM',solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('由右边往左编辑，总步数：5', ['DEL C', 'DEL G', 'DEL C', 'SUB C => G', 'SUB E => A'])"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser_solution('EBCMCGC', 'ABGM',solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('由右边往左编辑，总步数：9',\n",
       " ['DEL 9',\n",
       "  'DEL M',\n",
       "  'DEL F',\n",
       "  'DEL C',\n",
       "  'DEL B',\n",
       "  'SUB 7 => c',\n",
       "  'SUB 2 => 9',\n",
       "  'SUB 1 => 8',\n",
       "  'SUB c => 8'])"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser_solution('c1297BCFM9','8899c',solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "del solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('由右边往左编辑，总步数：10',\n",
       " ['DEL 9',\n",
       "  'DEL M',\n",
       "  'DEL F',\n",
       "  'DEL C',\n",
       "  'SUB B => A',\n",
       "  'SUB 7 => c',\n",
       "  'SUB 2 => 9',\n",
       "  'SUB 1 => 8',\n",
       "  'SUB c => 8',\n",
       "  'DEL 9',\n",
       "  'DEL 9',\n",
       "  'SUB 9 => E',\n",
       "  'ADD D',\n",
       "  'ADD F'])"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del solution\n",
    "solution = {}\n",
    "parser_solution('c1297BCFM9','8899cABDCEFMEDF',solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('A', 'A'): '',\n",
       " ('A', 'A1'): 'ADD 1',\n",
       " ('A', 'A12'): 'ADD 2',\n",
       " ('A', 'A123'): 'ADD 3',\n",
       " ('A', 'A123B'): 'ADD B',\n",
       " ('A', 'A123BC'): 'ADD C',\n",
       " ('A', 'A123BCC'): 'ADD C',\n",
       " ('A', 'A123BCC4'): 'ADD 4',\n",
       " ('A', 'A123BCC49'): 'ADD 9',\n",
       " ('A', 'A123BCC49E'): 'ADD E',\n",
       " ('AB', 'A'): 'DEL B',\n",
       " ('AB', 'A1'): 'SUB B => 1',\n",
       " ('AB', 'A12'): 'ADD 2',\n",
       " ('AB', 'A123'): 'ADD 3',\n",
       " ('AB', 'A123B'): '',\n",
       " ('AB', 'A123BC'): 'ADD C',\n",
       " ('AB', 'A123BCC'): 'ADD C',\n",
       " ('AB', 'A123BCC4'): 'ADD 4',\n",
       " ('AB', 'A123BCC49'): 'ADD 9',\n",
       " ('AB', 'A123BCC49E'): 'ADD E',\n",
       " ('ABC', 'A'): 'DEL C',\n",
       " ('ABC', 'A1'): 'DEL C',\n",
       " ('ABC', 'A12'): 'SUB C => 2',\n",
       " ('ABC', 'A123'): 'ADD 3',\n",
       " ('ABC', 'A123B'): 'DEL C',\n",
       " ('ABC', 'A123BC'): '',\n",
       " ('ABC', 'A123BCC'): 'ADD C',\n",
       " ('ABC', 'A123BCC4'): 'ADD 4',\n",
       " ('ABC', 'A123BCC49'): 'ADD 9',\n",
       " ('ABC', 'A123BCC49E'): 'ADD E'}"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 Choose 1 - 2 books to keep reading: \n",
    "\n",
    "+ SICP, Structure and Interpretation of Computer Programming. \n",
    "+ Introduction to Algorithms \n",
    "+ Artificial Intelligence A Modern Approach (3rd Edition) \n",
    "+ Code Complete 2 \n",
    "+ Programming Pearls \n",
    "+ Deep Learning\n",
    "+ 黑客与画家\n",
    "+ 数学之美\n",
    "+ Fluent Python\n",
    "+ Hands on Tensorflow\n",
    "+ Conference: NIPS_ ICML_ ICLR_ ACL_ AAAI\n",
    "\n",
    "> most books you may find in our github: https://github.com/Computing-Intelligence/References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5-1: review machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Why do we use Derivative / Gradient to fit a target function?¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:导数/梯度的变化直接影响目标函数值的变化，方向确定，更有利于快速找到目标。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. In the words 'Gradient Descent', what's the Gredient and what's the Descent?¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:Gradient是目标函数的导数，Descent是目标参数沿着导数反方向的变化，-1*Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. What's the advantages of the 3rd gradient descent method compared to the previous methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:方向确定，可控变化率/学习率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Using the simple words to describe: What's the machine leanring.¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:对已有数据进行建模（设定模拟函数），通过数据不断优化模型函数，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Answer following questions: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Why do we need dynamic programming? What's the difference of dynamic programming and previous talked `search` problme? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "在搜索中存在大量的重复计算工作，通过动态规划可以避免重复计算。区别在于动态规划会把已经计算过的数据存起来，而search没有，每次都重新计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Why do we still need dynamic programming? Why not we train a machine learning to fit a function which could get the `right` answer based on inputs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "搜索场景中涉及到的重复计算是随着搜索层数的递增，指数级上升，非常消耗cpu，耗费时间。动态规划能都大幅度梯度程序处理效率。机器学习建立的模型适用于特定场景，不是万能的，动态规划的思想则适应性更强。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Can you catch up at least 3 problems which could solved by Dynamic Programming? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "扫地机器人新建地图扫图、网页索引、外卖骑手路线规划"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Can you catch up at least 3 problems wich could sloved by Edit Distance? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "语言识别纠错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Please summarize the three main features of Dynamic Programming, and make a concise explain for each feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、分析子问题的重复性；\n",
    "2、子问题进行存储；\n",
    "3、Solution解析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What's the disadvantages of Dynamic Programming? (You may need search by yourself in Internet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main limitation to this type of coding is keeping track of previous decisions and partial choices that may be applied to a future answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6 Preparation of Project-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using python Flask or Bottle to finish your first simple web app:\n",
    "> https://bottlepy.org/\n",
    "\n",
    "2. Learn what's the SQL, and try some simple SQL operations:\n",
    "> https://www.w3schools.com/sql/sql_intro.asp\n",
    "\n",
    "3. Learn what's the HTML ( *ONLY* need to know the basic things)\n",
    "> https://getbootstrap.com/; https://www.w3schools.com/html/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part_6 Finished."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optinal) Finish the k-person-salesman problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitudes = [random.randint(-100, 100) for _ in range(20)]\n",
    "longitude = [random.randint(-100, 100) for _ in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x119d100f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(latitudes, longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定一个初始点 𝑃, 已经 𝑘个车辆，如何从该点出发，经这 k 个车辆经过所以的点全部一次，而且所走过的路程最短?\n",
    "\n",
    "例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_p = (-50, 10)\n",
    "chosen_p2 = (1, 30)\n",
    "chosen_p3 = (99, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x11dbbd470>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(latitudes, longitude)\n",
    "plt.scatter([chosen_p[0]], [chosen_p[1]], color='r')\n",
    "plt.scatter([chosen_p2[0]], [chosen_p2[1]], color='r')\n",
    "plt.scatter([chosen_p3[0]], [chosen_p3[1]], color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shuro"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
